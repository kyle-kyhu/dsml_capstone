{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic: Machine Learning from Disaster\n",
    "\n",
    "- Defining the problem statement\n",
    "- Collecting the data\n",
    "- Exploratory data analysis\n",
    "- Feature engineering\n",
    "- Modelling\n",
    "- Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Defining the problem statement\n",
    "- Complete the analysis of what sorts of people were likely to survive on the titanic.\n",
    "\n",
    "2. Collecting the data\n",
    "- Data came from kaggle here. \n",
    "https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('titanic/train.csv')\n",
    "test = pd.read_csv('titanic/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv('titanic/train.csv')\n",
    "\n",
    "sns.countplot(x='Survived', data=train)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='Survived', y='Fare', data=train)\n",
    "plt.show()\n",
    "\n",
    "train['Survived'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "sns.countplot(x='Age', data=test)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='Age', y='Fare', data=test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "train = pd.read_csv('titanic/train.csv')\n",
    "\n",
    "# Handle missing values\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "\n",
    "# Drop the cabin column\n",
    "train = train.drop(columns='Cabin')\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "train = pd.get_dummies(train, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "train[['Age', 'Fare']] = scaler.fit_transform(train[['Age', 'Fare']])\n",
    "\n",
    "# Feature Engineering\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train['IsAlone'] = (train['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Final DataFrame for modeling\n",
    "print(train.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charts(feature, figsize=(8, 6)):\n",
    "    survived = train[train['Survived'] == 1][feature].value_counts()\n",
    "    dead = train[train['Survived'] == 0][feature].value_counts()\n",
    "    df = pd.DataFrame([survived, dead])\n",
    "    df.index = ['Survived', 'Dead']\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    df.plot(kind='bar', stacked=True)\n",
    "    plt.show()\n",
    "\n",
    "charts('Sex', figsize=(5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woman survived more as woman boarded the boats first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts('Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st class survived more than other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=train)\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(x='Sex', y='Survived', data=train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Matrix (X) and Target Variable (y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the feature set (X) and target variable (y)\n",
    "X = train[['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone']]\n",
    "y = train['Survived']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and validation sets\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}, y_val shape: {y_val.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does this location make sense?\n",
    "\n",
    "train['Title'] = train['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "sns.barplot(x='Title', y='Survived', data=train)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logreg.predict(X_val)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negatives: model correctly predicted that 91 passengers did not survive.\n",
    "False Positives: model incorrectly predicted that 14 passengers survived, but they did not.\n",
    "False Negatives: model incorrectly predicted that 21 passengers did not survive, but they actually did.\n",
    "True Positives: model correctly predicted that 53 passengers survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Compute and display confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate Precision\n",
    "precision = precision_score(y_val, y_pred)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_val, y_pred)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_val, y_pred_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get feature importance from the Random Forest model\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "features = X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "\n",
    "# Sort by importance for a cleaner plot\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demostrating that fare is the most important feature for survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FacetGrid\n",
    "g = sns.FacetGrid(train, col=\"Survived\")\n",
    "g.map(plt.hist, \"Age\", bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Create a FacetGrid\n",
    "g = sns.FacetGrid(train, col=\"Survived\", hue=\"Sex\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.scatter, \"Age\", \"Fare\", alpha=.7)\n",
    "g.add_legend()\n",
    "plt.show()\n",
    "\n",
    "# # Create a FacetGrid with specified order for 'Sex'\n",
    "# g = sns.FacetGrid(train, row=\"Pclass\", col=\"Survived\", margin_titles=True)\n",
    "# g.map_dataframe(sns.boxplot, x=\"Sex\", y=\"Age\", order=['male', 'female'])\n",
    "# plt.show()\n",
    "\n",
    "# Create a PairGrid\n",
    "g = sns.PairGrid(train, hue=\"Survived\", vars=[\"Age\", \"Fare\", \"Pclass\"])\n",
    "g.map_diag(plt.hist)\n",
    "g.map_offdiag(plt.scatter)\n",
    "g.add_legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',fill= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',fill= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'F',fill= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test dataset\n",
    "test['Age'] = test['Age'].fillna(train['Age'].median())\n",
    "test['Fare'] = test['Fare'].fillna(train['Fare'].median())\n",
    "test = test.drop(columns='Cabin')\n",
    "test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "test = pd.get_dummies(test, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Feature Scaling\n",
    "test[['Age', 'Fare']] = scaler.transform(test[['Age', 'Fare']])\n",
    "\n",
    "# Feature Engineering\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "test['IsAlone'] = (test['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Define the feature set for the test dataset\n",
    "X_test = test[['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone']]\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('titanic_submission.csv', index=False)\n",
    "\n",
    "print(\"Testing and submission file creation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
